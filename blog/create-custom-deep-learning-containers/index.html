<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Zain Rizvi"><meta property="og:type" content="article"><meta property="og:image" content="https://images.unsplash.com/photo-1511578194003-00c80e42dc9b?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ"><meta property="twitter:image" content="https://images.unsplash.com/photo-1511578194003-00c80e42dc9b?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ"><meta name=title content="How to Create Customized Deep Learning Containers"><meta property="og:title" content="How to Create Customized Deep Learning Containers"><meta property="twitter:title" content="How to Create Customized Deep Learning Containers"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="summary"><meta name=keyword content><link rel="shortcut icon" href=../../img/favicon.ico><title>How to Create Customized Deep Learning Containers | </title><link rel=canonical href=../../blog/create-custom-deep-learning-containers/><link rel=stylesheet href=../../css/bootstrap.min.css><link rel=stylesheet href=../../css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=../../css/zanshang.css><link rel=stylesheet href=../../css/font-awesome.all.min.css><link rel=stylesheet href=https://transcriptionproject.github.io/blog/css/custom.css><script src=../../js/jquery.min.js></script><script src=../../js/bootstrap.min.js></script><script src=../../js/hux-blog.min.js></script><script src=../../js/lazysizes.min.js></script><script src=https://transcriptionproject.github.io/blog/js/author-box.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class=site-header-inside style="padding:0 40px"><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button><div class=site-branding><h1 class=site-title><a class=navbar-brand href=../../ style=font-size:1.5em>Zain Rizvi</a></h1></div></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li class="menu-item current-menu-item"><a href=../../>Start Here</a></li><li class=menu-item><a href=../../blog/>Essays</a></li><li class=menu-item><a href=../../newsletter/>Newsletter</a></li><li class=menu-item><a href=https://www.thenonintuitivebits.com/>Podcast</a></li><li class=menu-item><a href=https://zainrizvi.gumroad.com/l/insider-advice-on-how-you-can-pass-faang-interviews/site_header>Insider's Guide to Passing FAANG Interviews</a></li></ul></div></div></div></div></nav><style type=text/css>header.intro-header{background-image:url(https://images.unsplash.com/photo-1511578194003-00c80e42dc9b?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags></div><h1>How to Create Customized Deep Learning Containers</h1><h2 class=subheading></h2><span class=meta>Posted by
Zain Rizvi
on
Tuesday, December 17, 2019</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><p>Ever find yourself needing to install the same packages on all your deep learning notebooks? Or maybe wishing you could send your exact setup to someone else who could run your notebook? Or perhaps you’re a corporation which wants all your data scientists to have some internal libraries on all their notebooks.</p><p>Turns out you can. GCP’s <a href=https://cloud.google.com/ai-platform-notebooks/>AI Platform Notebooks team</a> offers <a href=https://cloud.google.com/ai-platform/deep-learning-containers/>Deep Learning Containers</a>, which is a containerized version of the exact same images you get when you create a regular AI Platform Notebook (full disclosure: that’s <a href=https://zainrizvi.io/about/>my team</a>).</p><p>And those containers are 100% free</p><p>Why would you want to use one? A quick list of benefits you can expect by using these:</p><ul><li>Ability to run these deep learning environments anywhere, including directly on your laptop</li><li>Have your favorite libraries pre-installed by default. You avoid having to customize your notebook environment every time you create a new notebook</li><li>Have a consistent environment used by all of your data scientists</li><li>Ability to modify or replace the default Jupyter Lab IDE (if you really want to)</li></ul><p>Below I’ll be walking you through the steps I took to create a Jupyter Lab container that lets you run Tensorflow with GPUs, but you can modify these instructions to meet your own exact needs.</p><p><strong><strong>Disclaimer</strong></strong>: While my team offers the Deep Learning containers (among other products), I myself have never used containers before. So the below is the results of my first real experimentation and if you know of better ways to achieve what I’m doing please let me know in the comments!</p><p>At the bottom of the post are the key lessons I learned:</p><ul><li>Differences between DLVM images and DL Container images</li><li>Some productivity hacks for working with Dockerfiles</li></ul><h1 id=prerequisites><strong><strong>Prerequisites</strong></strong></h1><p>In order to follow along with the rest of the post I’ll assume you have the following installed on your computer:</p><ul><li>docker</li><li>gcloud (optional)</li></ul><h1 id=download-a-container><strong><strong>Download a container</strong></strong></h1><p>Let’s take a quick look at what containers we have available to us by running</p><pre tabindex=0><code>$ gcloud container images list --repository=&#34;gcr.io/deeplearning-platform-release&#34;
</code></pre><p>Currently that command outputs:</p><pre tabindex=0><code>$ gcloud container images list --repository=&#34;gcr.io/deeplearning-platform-release&#34;
NAME
gcr.io/deeplearning-platform-release/base-cpu
gcr.io/deeplearning-platform-release/base-cu100
gcr.io/deeplearning-platform-release/beam-notebooks
gcr.io/deeplearning-platform-release/pytorch-cpu
gcr.io/deeplearning-platform-release/pytorch-cpu.1-0
gcr.io/deeplearning-platform-release/pytorch-cpu.1-1
gcr.io/deeplearning-platform-release/pytorch-cpu.1-2
gcr.io/deeplearning-platform-release/pytorch-cpu.1-3
gcr.io/deeplearning-platform-release/pytorch-gpu
gcr.io/deeplearning-platform-release/pytorch-gpu.1-0
gcr.io/deeplearning-platform-release/pytorch-gpu.1-1
gcr.io/deeplearning-platform-release/pytorch-gpu.1-2
gcr.io/deeplearning-platform-release/pytorch-gpu.1-3
gcr.io/deeplearning-platform-release/r-cpu
gcr.io/deeplearning-platform-release/r-cpu.3-6
gcr.io/deeplearning-platform-release/tf-cpu
gcr.io/deeplearning-platform-release/tf-cpu.1-13
gcr.io/deeplearning-platform-release/tf-cpu.1-14
gcr.io/deeplearning-platform-release/tf-cpu.1-15
gcr.io/deeplearning-platform-release/tf-gpu
gcr.io/deeplearning-platform-release/tf-gpu.1-13
gcr.io/deeplearning-platform-release/tf-gpu.1-14
gcr.io/deeplearning-platform-release/tf-gpu.1-15
gcr.io/deeplearning-platform-release/tf2-cpu
gcr.io/deeplearning-platform-release/tf2-cpu.2-0
gcr.io/deeplearning-platform-release/tf2-gpu
gcr.io/deeplearning-platform-release/tf2-gpu.2-0
</code></pre><p>That’s a list of all the different environments available for you to choose from. You can see Tensorflow, Pytorch, R, and others on the list, and most of them come in both CPU and GPU variations.</p><p>We’ll take the Tensorflow 2 CPU image and modify it to create our custom environment. My goal here is to create a containerized version of an R environment with support for using GPUs with Tensorflow available out of the box. <a href=https://zainrizvi.io/blog/using-gpus-with-r-in-jupyter-lab/>I previously walked through a script</a> that does all this for you on a AI Platform Notebook, but that script took tens of minutes to run and who has time to wait that long for each of their notebooks?</p><p>This solution will hopefully get us to the point where we get both of those things available in two minutes.</p><h1 id=steps><strong><strong>Steps</strong></strong></h1><p><em>You can follow along these instructions by cloning the</em> <a href=https://github.com/ZainRizvi/UseRWithGpus/><em>https://github.com/ZainRizvi/UseRWithGpus/</em></a> <em>repository and running the below commands from there</em></p><h2 id=1-create-your-image>1. Create your image</h2><p>We’ll create a super simple image first. We’ll use the Tensorflow 2 CPU image as our base and not change anything other than adding our own name as the maintainer of the new image.</p><p>To do this, create a dockerfile and give it the following contents</p><pre tabindex=0><code>FROM gcr.io/deeplearning-platform-release/tf2-gpu
LABEL maintainer=&#34;Zain Rizvi&#34;
</code></pre><p><strong><strong><em>Note</em></strong></strong><em>: I named my dockerfile</em> <a href=https://github.com/ZainRizvi/UseRWithGpus/blob/master/dockerfiles/tensorflow-2-gpu.Dockerfile><em>tensorflow-2-gpu.Dockerfile</em></a> <em>and put it under the “dockerfiles” subdirectory, and will be using that for the rest of my examples. But convention is to just name your dockerfile “Dockerfile”</em></p><p>Now cd to the directory that contains that file and run <code>docker build . -f dockerfiles\tensorflow-2-gpu.Dockerfiles</code> And Docker will download that image from the GCP repository, apply your custom label to it, and save the resulting image locally.</p><p><strong><strong><em>Note</em></strong></strong><em>: If you name your dockerfile “Dockerfile” and place it in your current directory, you can skip the</em> <code>-f [filename\]</code> <em>parameter.</em></p><p>You’ll see something similar to the following</p><pre tabindex=0><code>$ docker build . -f dockerfiles\tensorflow-2-gpu.Dockerfiles
Sending build context to Docker daemon 2.048kB
Step 1/2 : FROM gcr.io/deeplearning-platform-release/tf2-cpu
latest: Pulling from deeplearning-platform-release/tf2-cpu
35c102085707: Already exists
251f5509d51d: Already exists
…
928e12577c37: Pull complete
48d9ceba06f1: Pull complete
Digest: sha256:88ae24914e15f2df11a03486668e9051ca85b65f8577358e7d965ce6a146f217
Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-cpu:latest
---&gt; e493f17c90d0
Step 2/2 : LABEL maintainer=&#34;Zain Rizvi&#34;
---&gt; Running in 561cbb80b0c5
Removing intermediate container 561cbb80b0c5
---&gt; 8cee7adcf9c3
Successfully built 8cee7adcf9c3
</code></pre><p>Note the id in the last line <code>Successfully built 8cee7adcf9c3</code>. That <code>8cee7adcf9c3</code> is a local image id, and it will be important when we want to push our image (a couple steps down).</p><h2 id=2-push-your-image-to-a-repository>2. Push your image to a repository</h2><p>To push your image, you need a registry to push it to. I’ll assume you’re using Docker Hub (which is free for public registries) but you can use whatever registry provider you prefer. For a Docker Hub registry you can go to <a href=https://zainrizvi.io/blog/create-custom-deep-learning-containers/hub.docker.com>hub.docker.com</a> and create your public registry. You’ll need to create an account first though if you don’t have one already</p><p>Before the push, make sure you’re logged into docker from within the console (enter your password when prompted):</p><pre tabindex=0><code>$ docker login --username zainrizvi
</code></pre><p>Now to push we need to tell docker which image it should be pushing to our new registry. We do this by tagging the image we built with the path of our registry and add an optional tag (yeah, the overload of the word ‘tag’ is a bit annoying).</p><p>Remember that image Id I told you to note earlier (mine was <strong><strong><code>8cee7adcf9c3</code></strong></strong>), now is when you need that Id. We’ll tag that Id with the path to the repository we want to use:</p><pre tabindex=0><code>$ docker tag [ImageId] [repo-name]:[image-tag]
</code></pre><p>Example:</p><pre tabindex=0><code>$ docker tag 8cee7adcf9c3 zainrizvi/deeplearning-container-tf2-with-r:latest-gpu
</code></pre><p>If you run docker images you should now see an image with that repository and tag</p><pre tabindex=0><code>$ docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
zainrizvi/deeplearning-container-tf2-with-r latest-gpu 8cee7adcf9c3 4 minutes ago 6.26GB
</code></pre><p>However, just because we’ve tagged the image doesn’t mean it actually exists in the repository. We have to do a docker push to get it in there:</p><pre tabindex=0><code>$ docker push zainrizvi/deeplearning-container-tf2-with-r
</code></pre><p>And now if you go to your docker registry you’ll see that the image is there for anyone to view and download</p><p>So that was cool, but we didn’t really do anything special. We’re not pre-configuring any of the packages we really need or anything like that.</p><p>Let’s now add some actual customizations to this image</p><h2 id=3-customize-your-image><strong><strong>3. Customize your image</strong></strong></h2><p>Let’s extend this Dockerfile to support using Tensorflow with GPUs on an R notebook.</p><p>I’ve shared a few scripts on GitHub which can install R onto your AI Platform Notebooks, but those script takes way too long to run them every time you make a new notebook. Instead, I’d rather run the script in a container just once, and then save that container for future notebooks.</p><p>The scripts referenced below are chunks of logic I pulled out from these <a href=https://github.com/ZainRizvi/UseRWithGpus/blob/master/install-r-gpu.sh>master</a> <a href=https://github.com/ZainRizvi/UseRWithGpus/blob/master/install-r-cpu.sh>scripts</a>. You can read more about what those scripts do <a href=https://zainrizvi.io/blog/using-gpus-with-r-in-jupyter-lab/>in this blog post on using R with GPUs</a> . Splitting the logic into multiple scripts made this stuff much easier to debug (what problems did I run into that had to be debugged? I’ll tell you about it in a future post).</p><pre tabindex=0><code>FROM gcr.io/deeplearning-platform-release/tf2-gpu
LABEL maintainer=&#34;Zain Rizvi&#34;

RUN apt update -y
RUN mkdir steps
COPY steps/* /steps/
RUN chmod +x /steps/*

RUN /steps/1-Install-generic-dependencies.sh
RUN /steps/2-register-with-r-repository-ubuntu.sh
RUN /steps/3-Install-R-and-IRkernel.sh
RUN /steps/4-Install-common-R-packages.sh -m GPU
RUN /steps/5-Add-rpy2-support.sh
RUN /steps/6-Install-keras.sh
</code></pre><p>And now we can run <code>docker build . -f dockerfiles\tensorflow-2-gpu.Dockerfiles</code> again. This time the command will take a <strong><strong>long</strong></strong> time to complete (because some of those steps are sloooooow).</p><p>But once it completes, we’ll again be given a new image Id similar to the one we saw earlier. Just tag that and push it to your registry the same way we did before</p><pre tabindex=0><code>$ docker tag xxxxxxxxxxxxx zainrizvi/deeplearning-container-tf2-with-r:latest-gpu
$ docker push zainrizvi/deeplearning-container-tf2-with-r
</code></pre><p>And now your image is available to use on your registry</p><h1 id=use-your-image>Use your image!</h1><p>To use your newly created image on AI Platform Notebooks:</p><ol><li>Go to the <a href=https://console.cloud.google.com/ai-platform/notebooks/>notebooks page</a> -> New Instance -> Customize Instance</li></ol><link rel=stylesheet href=../../css/hugo-easy-gallery.css><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=../../img/create-custom-deep-learning-containers/2019-12-13-custom-instance-1-.png></div><a href=../../img/create-custom-deep-learning-containers/2019-12-13-custom-instance-1-.png itemprop=contentUrl></a></figure></div><ol><li>Under the environment drop down select “Custom container”</li></ol><p>Then in the “Docker container image” box enter the path to the registry you pushed your image to. Mine is: zainrizvi/deeplearning-container-tf2-with-r:latest-gpu</p><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=../../img/create-custom-deep-learning-containers/2019-12-13-custom-container-1-.png></div><a href=../../img/create-custom-deep-learning-containers/2019-12-13-custom-container-1-.png itemprop=contentUrl></a></figure></div><p>Click create, and in few minutes your notebook will be ready. You can open it up and see that TensorFlow is ready to go</p><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=../../img/create-custom-deep-learning-containers/2019-12-13-running-notebook-1-1-.png></div><a href=../../img/create-custom-deep-learning-containers/2019-12-13-running-notebook-1-1-.png itemprop=contentUrl></a></figure></div><p>And there you go, you now have an R notebook that can run Tensorflow on GPUs!</p><h1 id=it-wasnt-all-roses-and-rainbows>It wasn’t all Roses and Rainbows</h1><p>The more astute among you may have noticed that while <a href=https://zainrizvi.io/blog/using-gpus-with-r-in-jupyter-lab/>the script I previously demoed</a> was just, well, a single script, the dockerfile above contains six different scripts which seem to be the original script split into six parts. The eagle eyed may even notice that some parts of the script have been slightly changed, and that I’m no longer compiling XGboost.</p><p>Turns out the Deep Learning VM images and Deep Learning Containers are note quiiiiite 100% identical…</p><h2 id=key-differences-encountered><strong><strong>Key differences encountered:</strong></strong></h2><ul><li>VM images run on Debian OS while containers run on Ubuntu</li><li>Container images don’t the CUDA compiler installed, which is (surprise) required to compile GPU binaries. It contains all the binaries required for runtime though. Turns out those were omitted in order to reduce the size of the docker container.</li><li>[mild] Containers get very confused if you give them a command that starts with “sudo”. Not a big deal since every command in a container runs as ‘sudo’ anyways</li></ul><p>This led to a lot of time spent debugging what I had thought was a solved problem. (And did I mention this was my first time using docker containers?). Which led to…</p><h2 id=key-productivity-hacks-discovered><strong><strong>Key productivity hacks discovered:</strong></strong></h2><ul><li>In your dockerfile, split up your mega script into multiple smaller scripts. Docker will ‘cache’ the results of your previous, successful scripts and restart the build from the script that was changed (downside: this adds more layers to your docker image, but there are workarounds)</li><li>Edit on the go: If you setup docker hub to pull your code from github and build the image, you can make minor 1-minute fixes from your phone directly on github, commit, and go about your day while docker hub starts a new build run (which may take 2-4 hours to complete…Docker hub is slowwwwww. But it’s free, and enables this nice productivity hack)</li></ul><p>If you’d like to hear about the craziness I encountered debugging this image (it was over 7 hours of debugging + waiting for scripts to run), sign up on the form below to get an email when that article comes out.</p><hr><ul class=pager><li class=previous><a href=../../blog/using-gpus-with-r-in-jupyter-lab/ data-toggle=tooltip data-placement=top title="How to Use GPUs with R in Jupyter Lab">&larr;
Previous Post</a></li><li class=next><a href=../../blog/how-to-setup-a-free-custom-domain-email-address/ data-toggle=tooltip data-placement=top title="How to setup a Free Custom Domain Email Address">Next
Post &rarr;</a></li></ul></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"></ul><p class="copyright text-muted">Copyright &copy; Zain Rizvi 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){n=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),t=$(this).text(),i=$('<a href="'+o+'" rel="nofollow" title="'+t+'">'+t+"</a>"),s=$('<li class="'+n+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>